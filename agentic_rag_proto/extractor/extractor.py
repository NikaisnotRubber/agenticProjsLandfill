import os
import re
import langextract as lx
from typing import Union, Iterable, List, Dict, Iterator
from langextract.data import Document 


class DocumentCollector:
    """æ”¶é›†æ–‡æª”å…§å®¹ä¸¦è½‰æ›ç‚ºLangExtractæ‰€éœ€çš„Documentå°è±¡"""
    
    def __init__(self, file_path: str, extensions: List[str]):
        self.file_path = file_path
        self.extensions = extensions
        self.documents: Iterator[Document]
    
    def _enhanced_regex_extraction(self, documents: List[Dict]) -> List[Dict]:
        """Enhanced regex-based extraction with better patterns"""
        
        extracted_docs = []
        
        for doc in documents:
            metadata = {
                'service': 'unknown',
                'version': 'unknown',
                'doc_type': 'reference', 
                'rate_limits': [],
                'deprecated': False
            }
            
            title = doc.get('title', '')
            content = doc['content']
            
            # Extract service name from title
            service_match = re.search(r'([\w\s]+(?:API|Service))', title)
            if service_match:
                metadata['service'] = service_match.group(1).strip()
            
            # Extract version number
            version_match = re.search(r'v?([\d.]+)', title)
            if version_match:
                metadata['version'] = version_match.group(1)
            
            # Determine document type
            if 'troubleshooting' in title.lower():
                metadata['doc_type'] = 'troubleshooting'
            elif 'guide' in title.lower():
                metadata['doc_type'] = 'guide'
            else:
                metadata['doc_type'] = 'reference'
            
            # Extract rate limits
            rate_matches = re.findall(r'(\d+)\s*(?:requests?|req)[/\s]*(?:per\s*)?min', content.lower())
            metadata['rate_limits'] = [f"{r} req/min" for r in rate_matches]
            
            # Check for deprecation
            if 'deprecated' in content.lower():
                metadata['deprecated'] = True
            
            extracted_docs.append({
                'id': doc['id'],
                'title': doc['title'], 
                'content': doc['content'],
                'metadata': metadata
            })
        
        return extracted_docs

    def find_files_with_extensions(self) -> List[str]:
        """
        éæ­¸æŸ¥æ‰¾æŒ‡å®šå‰¯æª”åçš„æ–‡ä»¶
        
        :return: æ‰¾åˆ°çš„æ–‡ä»¶è·¯å¾‘åˆ—è¡¨
        """
        found_files = []

        if not os.path.isdir(self.file_path):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°ç›®éŒ„: {os.path.abspath(self.file_path)}")

        for dirpath, _, filenames in os.walk(self.file_path):
            for filename in filenames:
                if any(filename.endswith(ext) for ext in self.extensions):
                    file_path = os.path.join(dirpath, filename)
                    found_files.append(file_path)
                    print(f"æ‰¾åˆ°æ–‡ä»¶: {file_path}")

        print(f"æ‰¾åˆ°ç¨‹å¼æ–‡ä»¶å…± {len(found_files)} å€‹ã€‚")
        return found_files

    def load_file_content(self, file_path: str) -> str:
        """
        å®‰å…¨åœ°è¼‰å…¥å–®å€‹æ–‡ä»¶å…§å®¹
        
        :param file_path: æ–‡ä»¶è·¯å¾‘
        :return: æ–‡ä»¶å…§å®¹ï¼Œå‡ºéŒ¯æ™‚è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                print(f"âœ… æˆåŠŸè¼‰å…¥: {file_path} ({len(content)} å­—ç¬¦)")
                return content
        except UnicodeDecodeError:
            # å˜—è©¦å…¶ä»–ç·¨ç¢¼
            try:
                with open(file_path, 'r', encoding='gbk') as f:
                    content = f.read()
                    print(f"âœ… æˆåŠŸè¼‰å…¥ (GBKç·¨ç¢¼): {file_path}")
                    return content
            except Exception as e:
                print(f"âŒ ç·¨ç¢¼éŒ¯èª¤: {file_path} - {e}")
                return ""
        except FileNotFoundError:
            print(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {file_path}")
            return ""
        except PermissionError:
            print(f"âŒ æ²’æœ‰æ¬Šé™è®€å–æª”æ¡ˆ: {file_path}")
            return ""
        except Exception as e:
            print(f"âŒ è®€å–æª”æ¡ˆ {file_path} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return ""

    def create_langextract_document(self, file_path: str, content: str) -> Document:
        """
        å‰µå»ºLangExtract Documentå°è±¡
        
        :param file_path: æ–‡ä»¶è·¯å¾‘
        :param content: æ–‡ä»¶å…§å®¹
        :return: LangExtract Documentå°è±¡
        """
        # ä½¿ç”¨ç›¸å°è·¯å¾‘ä½œç‚ºdocument_idï¼Œæ›´ç°¡æ½”
        relative_path = os.path.relpath(file_path, self.file_path)
        
        # å‰µå»ºDocumentæ™‚ï¼Œç¢ºä¿åƒæ•¸æ­£ç¢º
        doc = Document(
            text=content,
            document_id=relative_path,
            
            # å¯ä»¥æ·»åŠ metadata
            # metadata={
            #     "full_path": file_path,
            #     "extension": Path(file_path).suffix,
            #     "size": len(content)
            # }
        )
        return doc

    def collect_documents_as_text(self) -> str:
        """
        æ”¶é›†æ‰€æœ‰æ–‡æª”ä¸¦åˆä½µç‚ºå–®ä¸€é•·æ–‡æœ¬ï¼Œä½¿ç”¨ç›¸å°è·¯å¾‘ä½œç‚ºç¯‡ç« æ¨™è¨˜
        
        :return: åˆä½µå¾Œçš„æ–‡æœ¬å…§å®¹
        """        
        found_files = self.find_files_with_extensions()
        print(f"æº–å‚™è¼‰å…¥ {len(found_files)} å€‹æª”æ¡ˆ...")

        successful_count = 0
        combined_text = ""
        
        for file_path in found_files:
            content = self.load_file_content(file_path)
            
            # åªè™•ç†éç©ºå…§å®¹
            if content and content.strip():
                try:
                    relative_path = os.path.relpath(file_path, self.file_path)
                    successful_count += 1
                    
                    # æ·»åŠ æ–‡ä»¶è·¯å¾‘æ¨™è¨˜å’Œå…§å®¹
                    combined_text += f"\n\n=== FILE: {relative_path} ===\n\n"
                    combined_text += content
                    
                    # é¡¯ç¤ºæ–‡ä»¶å…§å®¹é è¦½
                    preview = content[:100].replace('\n', '\\n')
                    print(f"ğŸ“„ æ–‡æª”è¼‰å…¥æˆåŠŸ: {os.path.basename(file_path)} - é è¦½: {preview}...")
                    
                except Exception as e:
                    print(f"âŒ è¼‰å…¥æ–‡æª”å¤±æ•— {file_path}: {e}")
                    continue
            else:
                print(f"âš ï¸ è·³éç©ºæ–‡ä»¶: {file_path}")

        print(f"\nâœ… æˆåŠŸè™•ç† {successful_count} å€‹æ–‡ä»¶")
        print(f"ğŸ“‹ åˆä½µæ–‡æœ¬é•·åº¦: {len(combined_text)} å­—ç¬¦")
        
        return combined_text


# å…¨å±€è®Šé‡
extensions = [".py", ".java", ".groovy", ".kt", ".js", ".ts", "tsx"]

file_path = "../docs"

prompt = """ 
# ç¨‹å¼ç¢¼çŸ¥è­˜æå–Agent

## ä»»å‹™
å¾ç¨‹å¼ç¢¼ä¸­æå–çµæ§‹åŒ–çŸ¥è­˜ï¼Œæ”¯æ´Java(Spring Boot)ã€Groovy(Jira Script Runner)ã€Pythonã€Goã€JS/TSã€Rubyé–‹ç™¼ã€‚

## æ–‡ä»¶æ ¼å¼èªªæ˜
è¼¸å…¥æ–‡æœ¬ä½¿ç”¨ `=== FILE: {relative_path} ===` æ¨™è¨˜åˆ†éš”ä¸åŒæ–‡ä»¶ï¼Œè«‹åœ¨æå–æ™‚æ³¨æ„æ–‡ä»¶ä¾†æºä¸¦åœ¨attributesä¸­åŒ…å«æ–‡ä»¶è·¯å¾‘ä¿¡æ¯ã€‚

## è¼¸å‡ºæ ¼å¼

### å‡½æ•¸/é¡åˆ¥
```markdown
**[èªè¨€] åç¨±**: `ClassName` æˆ– `functionName`
**ç”¨é€”**: ç°¡æ½”åŠŸèƒ½æè¿°
**åƒæ•¸**: param: Type - èªªæ˜
**è¿”å›å€¼**: ReturnType - èªªæ˜  
**ç‰¹æ®Šæ¨™è¨˜**: @æ³¨è§£ã€è£é£¾å™¨ç­‰
**æ–‡ä»¶ä¾†æº**: ç›¸å°æ–‡ä»¶è·¯å¾‘
**ä½¿ç”¨ç¯„ä¾‹**:
```[language]
// å¯¦éš›å¯åŸ·è¡Œçš„ç¨‹å¼ç¢¼ç¯„ä¾‹
```
**æ³¨æ„äº‹é …**: é‡è¦é™åˆ¶æˆ–é…ç½®éœ€æ±‚
```

### é…ç½®é …ç›®
```markdown
**é…ç½®**: `CONFIG_NAME`
**é¡å‹**: type | é è¨­å€¼
**ç”¨é€”**: é…ç½®ä½œç”¨
**æ–‡ä»¶ä¾†æº**: ç›¸å°æ–‡ä»¶è·¯å¾‘
**è¨­å®š**:
```
# ç’°å¢ƒè®Šæ•¸æˆ–é…ç½®æ–‡ä»¶è¨­å®šæ–¹å¼
```
```

## èªè¨€ç‰¹å®šé‡é»

- **Java/Spring**: @Component/@Service/@Controllerã€ä¾è³´æ³¨å…¥ã€application.yml
- **Groovy/Jira**: ComponentAccessorä½¿ç”¨ã€Issueæ“ä½œã€è‡ªå®šç¾©æ¬„ä½
- **Python**: Type hintsã€è£é£¾å™¨ã€ç•°å¸¸è™•ç†
- **Go**: interfaceã€error handlingã€struct tags
- **JS/TS**: async/awaitã€å‹åˆ¥å®šç¾©ã€æ¨¡çµ„å°å…¥
- **Ruby**: ActiveRecordé—œè¯ã€gemä¾è³´ã€æ–¹æ³•å®šç¾©

## è™•ç†æµç¨‹

1. **è­˜åˆ¥**: "[æª¢æ¸¬èªè¨€] + [æ¡†æ¶] + [æ–‡ä»¶è·¯å¾‘]"
2. **æå–**: æŒ‰æ ¼å¼æå–é—œéµAPIå’Œé…ç½®ï¼ŒåŒ…å«æ–‡ä»¶ä¾†æº
3. **é©—è­‰**: ç¢ºä¿ç¨‹å¼ç¢¼ç¯„ä¾‹å¯åŸ·è¡Œ
4. **ç¸½çµ**: "æå–å®Œæˆ: Xå€‹API, Yå€‹é…ç½®"

## å“è³ªè¦æ±‚

- å‡½æ•¸ç°½åå¿…é ˆæº–ç¢º
- ç¨‹å¼ç¢¼ç¯„ä¾‹ç¬¦åˆèªè¨€æ…£ä¾‹
- æ¨™è¨»ç‰ˆæœ¬å·®ç•°ï¼ˆå¦‚Spring Boot 2/3ï¼‰
- å¿…é ˆåœ¨attributesä¸­åŒ…å«file_pathä¿¡æ¯
- ä¸ç¢ºå®šæ™‚æ¨™è¨˜ `[éœ€é©—è­‰]`
"""

# Example for program documentation data extraction
program_doc_examples = [
    lx.data.ExampleData(
        text="""
=== FILE: scripts/jira/fieldManager.groovy ===

import com.atlassian.jira.component.ComponentAccessor
import com.atlassian.jira.issue.CustomFieldManager

def customField = ComponentAccessor.getCustomFieldManager().getCustomFieldObject("customfield_19210")
def projectAtr = issue.getCustomFieldValue(customField)?.toString()

def mappingTable = [
    "Immersive Experience Creator": "Singyu.Liu",
    "Opportunity Lifecycle Management": "SAM.SHIH",
    "Smart e-Learning": "Hongyi.Du",
]

def corpStrategyVal = issue.getCustomFieldValue(corpStrategyId) as Map

if (mappingTable.containsKey(lastVal)) {
    programManagerVal = Users.getByName(mappingTable[lastVal])
}
""",
        extractions=[
            lx.data.Extraction(
                extraction_class="import_statement",
                extraction_text="import com.atlassian.jira.component.ComponentAccessor",
                attributes={"package": "com.atlassian.jira.component.ComponentAccessor", "file_path": "scripts/jira/fieldManager.groovy"}
            ),
            lx.data.Extraction(
                extraction_class="jira_field",
                extraction_text="customfield_19210",
                attributes={"field_type": "custom_field", "usage": "project attribute", "file_path": "scripts/jira/fieldManager.groovy"}
            ),
            lx.data.Extraction(
                extraction_class="function_name",
                extraction_text="getCustomFieldObject",
                attributes={"context": "accessing Jira custom field", "file_path": "scripts/jira/fieldManager.groovy"}
            ),
            lx.data.Extraction(
                extraction_class="configuration_parameter",
                extraction_text="mappingTable",
                attributes={"type": "key-value mapping", "purpose": "program manager assignment", "file_path": "scripts/jira/fieldManager.groovy"}
            ),
        ]
    )
]

combined_text = DocumentCollector(file_path=file_path, extensions=extensions).collect_documents_as_text()

print(f"åˆä½µæ–‡æœ¬æº–å‚™å®Œæˆï¼Œé–‹å§‹é€²è¡ŒçŸ¥è­˜æå–...")
try: 
    result = lx.extract(
        text_or_documents=combined_text,
        prompt_description=prompt,
        examples=program_doc_examples,
        model_id="gemini-2.5-flash",  # Automatically selects OpenAI provider
        api_key=os.environ.get('GEMINI_API_KEY'),

        # model_id=os.environ.get('OPENAI_MODEL', 'delta-agentic-coding'),  # Automatically selects OpenAI provider
        # api_key=os.environ.get('OPENAI_API_KEY'),
        # model_url=os.environ.get('OPENAI_BASE_URL'),
        max_workers=16,
        fence_output=False,
        use_schema_constraints=True
    )
    print("åˆ‡åˆ†çµæœçš„å‰åå€‹åˆ‡å¡Šæ˜¯ï¼š")
    for res in result.extractions[:5]:
        print(f"{res}\n")
except Exception as e:
    print(f"âŒ éŒ¯èª¤: {e}")
