import os
import re
import time
import langextract as lx
from typing import Union, Iterable, List, Dict, Iterator
from langextract.data import Document 
# To-do: add multi-modal

def _process_and_normalize(extractions, doc: Dict) -> Dict:
    """Process LangExtract results and normalize them"""
    
    metadata = {
        'code_with_comment': '',
        'import_statement': '',
        'jira_field': '', 
        'function_name': '',
    }

    # metadatas = []

    for extraction in extractions:
        if extraction.extraction_class == "import_statement":
            metadata['import_statement'] = extraction.extraction_text
        elif extraction.extraction_class == "code_with_comment":
            metadata['code_with_comment'] = extraction.extraction_text
        elif extraction.extraction_class == "jira_field":
            metadata['jira_field'] = extraction.extraction_text
        elif extraction.extraction_class == "function_name":
            metadata['function_name'] = extraction.extraction_text.lower()
        else :
            metadata[extraction.extraction_class] = extraction.extraction_text

        # metadatas.append(metadata)

    return metadata

class DocumentCollector:
    """æ”¶é›†æ–‡æª”å…§å®¹ä¸¦è½‰æ›ç‚ºLangExtractæ‰€éœ€çš„Documentå°è±¡"""
    
    def __init__(self, file_path: str, extensions: List[str]):
        self.file_path = file_path
        self.extensions = extensions
        self.documents: List[Dict] = []
  

    def find_files_with_extensions(self) -> List[str]:
        """
        éæ­¸æŸ¥æ‰¾æŒ‡å®šå‰¯æª”åçš„æ–‡ä»¶
        
        :return: æ‰¾åˆ°çš„æ–‡ä»¶è·¯å¾‘åˆ—è¡¨
        """
        found_files = []

        if not os.path.isdir(self.file_path):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°ç›®éŒ„: {os.path.abspath(self.file_path)}")

        for dirpath, _, filenames in os.walk(self.file_path):
            for filename in filenames:
                if any(filename.endswith(ext) for ext in self.extensions):
                    file_path = os.path.join(dirpath, filename)
                    found_files.append(file_path)
                    print(f"æ‰¾åˆ°æ–‡ä»¶: {file_path}")

        print(f"æ‰¾åˆ°ç¨‹å¼æ–‡ä»¶å…± {len(found_files)} å€‹ã€‚")
        return found_files

    def load_file_content(self, file_path: str) -> str:
        """
        å®‰å…¨åœ°è¼‰å…¥å–®å€‹æ–‡ä»¶å…§å®¹
        
        :param file_path: æ–‡ä»¶è·¯å¾‘
        :return: æ–‡ä»¶å…§å®¹ï¼Œå‡ºéŒ¯æ™‚è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                print(f"âœ… æˆåŠŸè¼‰å…¥: {file_path} ({len(content)} å­—ç¬¦)")
                return content
        except UnicodeDecodeError:
            # å˜—è©¦å…¶ä»–ç·¨ç¢¼
            try:
                with open(file_path, 'r', encoding='gbk') as f:
                    content = f.read()
                    print(f"âœ… æˆåŠŸè¼‰å…¥ (GBKç·¨ç¢¼): {file_path}")
                    return content
            except Exception as e:
                print(f"âŒ ç·¨ç¢¼éŒ¯èª¤: {file_path} - {e}")
                return ""
        except FileNotFoundError:
            print(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {file_path}")
            return ""
        except PermissionError:
            print(f"âŒ æ²’æœ‰æ¬Šé™è®€å–æª”æ¡ˆ: {file_path}")
            return ""
        except Exception as e:
            print(f"âŒ è®€å–æª”æ¡ˆ {file_path} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return ""

    def create_langextract_document(self, file_path: str, content: str) -> Dict:
        """
        å‰µå»ºLangExtract Documentå°è±¡
        
        :param file_path: æ–‡ä»¶è·¯å¾‘
        :param content: æ–‡ä»¶å…§å®¹
        :return: LangExtract Documentå°è±¡
        """
        # ä½¿ç”¨ç›¸å°è·¯å¾‘ä½œç‚ºdocument_idï¼Œæ›´ç°¡æ½”
        relative_path = os.path.relpath(file_path, self.file_path)
        
        # å‰µå»ºDocumentæ™‚ï¼Œç¢ºä¿åƒæ•¸æ­£ç¢º
        doc = {
            "text":content,
            "document_id":relative_path,
            
            # å¯ä»¥æ·»åŠ metadata
            # metadata={
            #     "full_path": file_path,
            #     "extension": Path(file_path).suffix,
            #     "size": len(content)
            # }
        }
        return doc

    def collect_documents_as_text(self) -> str:
        """
        æ”¶é›†æ‰€æœ‰æ–‡æª”ä¸¦åˆä½µç‚ºå–®ä¸€é•·æ–‡æœ¬ï¼Œä½¿ç”¨ç›¸å°è·¯å¾‘ä½œç‚ºç¯‡ç« æ¨™è¨˜
        
        :return: åˆä½µå¾Œçš„æ–‡æœ¬å…§å®¹
        """        
        found_files = self.find_files_with_extensions()
        print(f"æº–å‚™è¼‰å…¥ {len(found_files)} å€‹æª”æ¡ˆ...")

        successful_count = 0
        combined_text = ""
        
        for file_path in found_files:
            content = self.load_file_content(file_path)
            
            # åªè™•ç†éç©ºå…§å®¹
            if content and content.strip():
                try:
                    relative_path = os.path.relpath(file_path, self.file_path)
                    successful_count += 1
                    
                    # æ·»åŠ æ–‡ä»¶è·¯å¾‘æ¨™è¨˜å’Œå…§å®¹
                    combined_text += f"\n\n=== FILE: {relative_path} ===\n\n"
                    combined_text += content
                    
                    # é¡¯ç¤ºæ–‡ä»¶å…§å®¹é è¦½
                    preview = content[:100].replace('\n', '\\n')
                    print(f"ğŸ“„ æ–‡æª”è¼‰å…¥æˆåŠŸ: {os.path.basename(file_path)} - é è¦½: {preview}...")
                    
                except Exception as e:
                    print(f"âŒ è¼‰å…¥æ–‡æª”å¤±æ•— {file_path}: {e}")
                    continue
            else:
                print(f"âš ï¸ è·³éç©ºæ–‡ä»¶: {file_path}")

        print(f"\nâœ… æˆåŠŸè™•ç† {successful_count} å€‹æ–‡ä»¶")
        print(f"ğŸ“‹ åˆä½µæ–‡æœ¬é•·åº¦: {len(combined_text)} å­—ç¬¦")
        
        return combined_text
    def collect_documents(self) -> List[Dict]:
        """
        æ”¶é›†æ‰€æœ‰æ–‡æª”ä¸¦è½‰æ›ç‚ºLangExtract Documentå°è±¡
        
        :return: Documentå°è±¡åˆ—è¡¨
        """
        # æ¸…ç©ºä¹‹å‰çš„çµæœ
        self.documents = []
        
        found_files = self.find_files_with_extensions()
        print(f"æº–å‚™è¼‰å…¥ {len(found_files)} å€‹æª”æ¡ˆ...")

        successful_count = 0
        
        for file_path in found_files:
            content = self.load_file_content(file_path)
            
            # åªè™•ç†éç©ºå…§å®¹
            if content and content.strip():
                try:
                    doc = self.create_langextract_document(file_path, content)
                    self.documents.append(doc)
                    successful_count += 1
                    
                    # é¡¯ç¤ºæ–‡ä»¶å…§å®¹é è¦½
                    preview = content[:100].replace('\n', '\\n')
                    print(f"ğŸ“„ æ–‡æª”å‰µå»ºæˆåŠŸ: {os.path.basename(file_path)} - é è¦½: {preview}...")
                    
                except Exception as e:
                    print(f"âŒ å‰µå»ºæ–‡æª”å¤±æ•— {file_path}: {e}")
                    continue
            else:
                print(f"âš ï¸ è·³éç©ºæ–‡ä»¶: {file_path}")

        print(f"\nâœ… æˆåŠŸè™•ç† {successful_count}/{len(found_files)} å€‹æ–‡ä»¶")
        print(f"ğŸ“‹ ç¸½å…±å‰µå»º {len(self.documents)} å€‹Documentå°è±¡")
        
        return self.documents

class Extractor:
    def __init__(self):
        print("âœ… LangExtract initialized")

    def langExtractor():
        # å…¨å±€è®Šé‡
        extensions = [".py", ".java", ".groovy", ".kt", ".js", ".ts", "tsx"]

        file_path = "KnowledgeBase/docs"

        prompt = """ 
        # ç¨‹å¼ç¢¼çŸ¥è­˜æå–Agent

        ## ä»»å‹™
        å¾ç¨‹å¼ç¢¼ä¸­æå–çµæ§‹åŒ–çŸ¥è­˜ï¼Œæ”¯æ´Java(Spring Boot)ã€Groovy(Jira Script Runner)ã€Pythonã€Goã€JS/TSã€Rubyé–‹ç™¼ã€‚

        ## æ–‡ä»¶æ ¼å¼èªªæ˜
        è¼¸å…¥æ–‡æœ¬ä½¿ç”¨ `=== FILE: {relative_path} ===` æ¨™è¨˜åˆ†éš”ä¸åŒæ–‡ä»¶ï¼Œè«‹åœ¨æå–æ™‚æ³¨æ„æ–‡ä»¶ä¾†æºä¸¦åœ¨attributesä¸­åŒ…å«æ–‡ä»¶è·¯å¾‘ä¿¡æ¯ã€‚

        ## è¼¸å‡ºæ ¼å¼

        ### å‡½æ•¸/é¡åˆ¥
        ```markdown
        **[èªè¨€] åç¨±**: `ClassName` æˆ– `functionName`
        **ç”¨é€”**: ç°¡æ½”åŠŸèƒ½æè¿°
        **åƒæ•¸**: param: Type - èªªæ˜
        **è¿”å›å€¼**: ReturnType - èªªæ˜  
        **ç‰¹æ®Šæ¨™è¨˜**: @æ³¨è§£ã€è£é£¾å™¨ç­‰
        **æ–‡ä»¶ä¾†æº**: ç›¸å°æ–‡ä»¶è·¯å¾‘
        **ä½¿ç”¨ç¯„ä¾‹**:
        ```[language]
        // å¯¦éš›å¯åŸ·è¡Œçš„ç¨‹å¼ç¢¼ç¯„ä¾‹
        ```
        **æ³¨æ„äº‹é …**: é‡è¦é™åˆ¶æˆ–é…ç½®éœ€æ±‚
        ```

        ### é…ç½®é …ç›®
        ```markdown
        **é…ç½®**: `CONFIG_NAME`
        **é¡å‹**: type | é è¨­å€¼
        **ç”¨é€”**: é…ç½®ä½œç”¨
        **æ–‡ä»¶ä¾†æº**: ç›¸å°æ–‡ä»¶è·¯å¾‘
        **è¨­å®š**:
        ```
        # ç’°å¢ƒè®Šæ•¸æˆ–é…ç½®æ–‡ä»¶è¨­å®šæ–¹å¼
        ```
        ```

        ## èªè¨€ç‰¹å®šé‡é»

        - **Java/Spring**: @Component/@Service/@Controllerã€ä¾è³´æ³¨å…¥ã€application.yml
        - **Groovy/Jira**: ComponentAccessorä½¿ç”¨ã€Issueæ“ä½œã€è‡ªå®šç¾©æ¬„ä½
        - **Python**: Type hintsã€è£é£¾å™¨ã€ç•°å¸¸è™•ç†
        - **Go**: interfaceã€error handlingã€struct tags
        - **JS/TS**: async/awaitã€å‹åˆ¥å®šç¾©ã€æ¨¡çµ„å°å…¥
        - **Ruby**: ActiveRecordé—œè¯ã€gemä¾è³´ã€æ–¹æ³•å®šç¾©

        ## è™•ç†æµç¨‹

        1. **è­˜åˆ¥**: "[æª¢æ¸¬èªè¨€] + [æ¡†æ¶] + [æ–‡ä»¶è·¯å¾‘]"
        2. **æå–**: æŒ‰æ ¼å¼æå–é—œéµAPIå’Œé…ç½®ï¼ŒåŒ…å«æ–‡ä»¶ä¾†æº
        3. **é©—è­‰**: ç¢ºä¿ç¨‹å¼ç¢¼ç¯„ä¾‹å¯åŸ·è¡Œ
        4. **ç¸½çµ**: "æå–å®Œæˆ: Xå€‹API, Yå€‹é…ç½®"

        ## å“è³ªè¦æ±‚

        - å‡½æ•¸ç°½åå¿…é ˆæº–ç¢º
        - ç¨‹å¼ç¢¼ç¯„ä¾‹ç¬¦åˆèªè¨€æ…£ä¾‹
        - æ¨™è¨»ç‰ˆæœ¬å·®ç•°ï¼ˆå¦‚Spring Boot 2/3ï¼‰
        - å¿…é ˆåœ¨attributesä¸­åŒ…å«file_pathä¿¡æ¯
        - ä¸ç¢ºå®šæ™‚æ¨™è¨˜ `[éœ€é©—è­‰]`
        """

        # Example for program documentation data extraction
        program_doc_examples = [
            lx.data.ExampleData(
                text="""
        === FILE: scripts/jira/fieldManager.groovy ===

        import com.atlassian.jira.component.ComponentAccessor
        import com.atlassian.jira.issue.CustomFieldManager
        # use ComponentAccessor.getCustomFieldManager() to initiate a manager for custumfield
        def customField = ComponentAccessor.getCustomFieldManager().getCustomFieldObject("customfield_19210")
        def projectAtr = issue.getCustomFieldValue(customField)?.toString()

        def mappingTable = [
            "Immersive Experience Creator": "Liu",
            "Opportunity Lifecycle Management": "SHIH",
            "Smart e-Learning": "Du",
        ]

        def corpStrategyVal = issue.getCustomFieldValue(corpStrategyId) as Map

        if (mappingTable.containsKey(lastVal)) {
            programManagerVal = Users.getByName(mappingTable[lastVal])
        }
        """,
                extractions=[
                    lx.data.Extraction(
                        extraction_class="code_with_comment",
                        extraction_text="# use ComponentAccessor.getCustomFieldManager() to initiate a manager for custumfield" + "def customField = ComponentAccessor.getCustomFieldManager().getCustomFieldObject(""customfield_19210"")",
                        attributes={"package": "com.atlassian.jira.component.ComponentAccessor", "usage": "use ComponentAccessor.getCustomFieldManager() to initiate a manager for custumfield"}
                    ),
                    lx.data.Extraction(
                        extraction_class="import_statement",
                        extraction_text="import com.atlassian.jira.component.ComponentAccessor",
                        attributes={"package": "com.atlassian.jira.component.ComponentAccessor", "file_path": "scripts/jira/fieldManager.groovy"}
                    ),
                    lx.data.Extraction(
                        extraction_class="jira_field",
                        extraction_text="customfield_19210",
                        attributes={"field_type": "custom_field", "usage": "project attribute", "file_path": "scripts/jira/fieldManager.groovy"}
                    ),
                    lx.data.Extraction(
                        extraction_class="function_name",
                        extraction_text="getCustomFieldObject",
                        attributes={"context": "accessing Jira custom field", "file_path": "scripts/jira/fieldManager.groovy"}
                    ),
                    lx.data.Extraction(
                        extraction_class="configuration_parameter",
                        extraction_text="mappingTable",
                        attributes={"type": "key-value mapping", "purpose": "program manager assignment", "file_path": "scripts/jira/fieldManager.groovy"}
                    ),
                ]
            )
        ]

        extracted_docs = []
        documents = DocumentCollector(file_path, extensions).collect_documents()
        data = {}
        for doc in documents:
            print(f"ğŸ“„ Processing: {doc["document_id"]}")

            
            result = lx.extract(
                text_or_documents=doc["text"],
                prompt_description=prompt,
                examples=program_doc_examples,
                model_id="gemini-2.5-flash",
            )
            
            # Process and normalize extractions
            data = _process_and_normalize(result.extractions, doc)

            print(f"{data}\n")
            
            time.sleep(3)
            extracted_docs.append({
                'id': doc['document_id'],
                'content': doc['text'],
                'metadata': data
            })
        
        return extracted_docs